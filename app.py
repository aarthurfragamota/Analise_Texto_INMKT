import streamlit as st
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
from io import BytesIO
import nltk
from nltk.corpus import stopwords
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import stanza
import os
import base64
import zipfile
from PIL import Image
import io

# Configura√ß√µes de ambiente
os.environ['STANZA_RESOURCES_DIR'] = r"D:\stanza_resources"
os.environ['TRANSFORMERS_CACHE'] = r"D:\hf_cache"

# Download recursos (apenas primeira execu√ß√£o)
@st.cache_resource
def download_recursos():
    nltk.download('stopwords')
    try:
        stanza.download('pt')
    except:
        pass  # J√° baixado

download_recursos()

# ========================
# üîß CONFIGURA√á√ÉO STREAMLIT
# ========================
st.set_page_config(page_title="Analisador Completo de Texto", layout="wide")
st.title("üìä Analisador de Sentimento + Sintaxe + Nuvens")

# ========================
# ‚öôÔ∏è INICIALIZAR SESSION STATE
# ========================
if 'analise_feita' not in st.session_state:
    st.session_state.analise_feita = False
if 'df_analisado' not in st.session_state:
    st.session_state.df_analisado = None
if 'df_sintatica' not in st.session_state:
    st.session_state.df_sintatica = None
if 'nuvens' not in st.session_state:
    st.session_state.nuvens = {}
if 'text_col' not in st.session_state:
    st.session_state.text_col = None
if 'tipo_analise' not in st.session_state:
    st.session_state.tipo_analise = None

# ========================
# ‚öôÔ∏è CARREGAR MODELOS (COM CACHE CORRETO)
# ========================
_modelo_sentimento_carregado = False

@st.cache_resource
def carregar_modelo_sentimento():
    global _modelo_sentimento_carregado
    if not _modelo_sentimento_carregado:
        st.sidebar.info("Carregando modelo RoBERTuito... ‚è≥")
        _modelo_sentimento_carregado = True
    
    model_name = "pysentimiento/robertuito-sentiment-analysis"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    return pipeline(
        "sentiment-analysis",
        model=model,
        tokenizer=tokenizer,
        device=0 if torch.cuda.is_available() else -1
    )

@st.cache_resource
def carregar_modelo_sintaxe():
    return stanza.Pipeline('pt', use_gpu=torch.cuda.is_available())

# ========================
# üß† FUN√á√ïES DE AN√ÅLISE
# ========================
def gerar_nuvem(textos, titulo, stopwords_set=None):
    if textos.empty:
        st.warning(f"‚ö†Ô∏è N√£o h√° dados para gerar a nuvem: {titulo}")
        return None
        
    textos = textos.dropna().astype(str)
    texto = " ".join(textos)
    
    if not incluir_acentos:
        import unicodedata
        texto = ''.join(
            c for c in unicodedata.normalize('NFD', texto)
            if unicodedata.category(c) != 'Mn'
        )

    wc = WordCloud(
        width=800,
        height=400,
        background_color="white",
        max_words=top_n,
        stopwords=stopwords_set or stop_words,
        collocations=False
    ).generate(texto)
    
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wc, interpolation="bilinear")
    ax.axis("off")
    ax.set_title(titulo, fontsize=14, pad=20)
    
    # Converter figura para bytes
    buf = BytesIO()
    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
    plt.close(fig)
    buf.seek(0)
    return buf

def gerar_nuvem_por_classe(df_sintatica, classe_gramatical, titulo):
    """Gera nuvem de palavras para uma classe gramatical espec√≠fica"""
    palavras_filtradas = df_sintatica[df_sintatica['classe_gramatical'] == classe_gramatical]
    
    if palavras_filtradas.empty:
        st.warning(f"‚ö†Ô∏è N√£o h√° {titulo.lower()} para gerar nuvem")
        return None
        
    texto = " ".join(palavras_filtradas['palavra'].astype(str))
    
    if not incluir_acentos:
        import unicodedata
        texto = ''.join(
            c for c in unicodedata.normalize('NFD', texto)
            if unicodedata.category(c) != 'Mn'
        )

    wc = WordCloud(
        width=600,
        height=300,
        background_color="white",
        max_words=top_n,
        stopwords=stop_words,
        collocations=False
    ).generate(texto)
    
    fig, ax = plt.subplots(figsize=(8, 4))
    ax.imshow(wc, interpolation="bilinear")
    ax.axis("off")
    ax.set_title(titulo, fontsize=12, pad=15)
    
    # Converter figura para bytes
    buf = BytesIO()
    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
    plt.close(fig)
    buf.seek(0)
    return buf

def classificar_sentimento_batch(_sentiment_analyzer, textos):
    """Classifica sentimentos em lote para melhor performance"""
    resultados = []
    for texto in textos:
        try:
            if pd.isna(texto) or texto.strip() == "":
                resultados.append(("NEUTRO", 0.0))
                continue
                
            texto = str(texto)[:512]
            resultado = _sentiment_analyzer(texto)[0]
            label = resultado['label']
            score = resultado['score']
            
            if label == 'POS':
                resultados.append(("POSITIVO", score))
            elif label == 'NEG':
                resultados.append(("NEGATIVO", score))
            else:
                resultados.append(("NEUTRO", score))
        except Exception as e:
            st.warning(f"Erro ao analisar texto: {e}")
            resultados.append(("ERRO", 0.0))
            
    return resultados

def analisar_sintatica(textos):
    nlp = carregar_modelo_sintaxe()
    resultados = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    textos_lista = textos.dropna().tolist()
    
    for i, texto in enumerate(textos_lista):
        status_text.text(f"Analisando sintaxe: {i+1}/{len(textos_lista)}")
        progress_bar.progress((i + 1) / len(textos_lista))
        
        try:
            doc = nlp(str(texto))
            for sent in doc.sentences:
                for word in sent.words:
                    resultados.append({
                        "texto_original": texto[:100] + "..." if len(str(texto)) > 100 else texto,
                        "palavra": word.text,
                        "lema": word.lemma,
                        "classe_gramatical": word.upos,
                        "classe_detalhada": word.xpos,
                        "caracter√≠sticas": word.feats,
                        "relacao_sintatica": word.deprel,
                        "palavra_pai": sent.words[word.head-1].text if word.head > 0 else "ROOT"
                    })
        except Exception as e:
            st.warning(f"Erro na an√°lise sint√°tica do texto {i+1}: {e}")
    
    progress_bar.empty()
    status_text.empty()
    return pd.DataFrame(resultados)

# ========================
# üìÅ SIDEBAR - CONFIGURA√á√ïES
# ========================
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # Upload de arquivo
    uploaded_file = st.file_uploader("Envie sua planilha (.xlsx ou .csv)", type=["xlsx", "csv"])
    
    if uploaded_file:
        try:
            if uploaded_file.name.endswith(".csv"):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
        except Exception as e:
            st.error(f"Erro ao ler arquivo: {e}")
            st.stop()

        st.success("‚úÖ Arquivo carregado com sucesso!")
        
        with st.expander("üìã Visualizar dados"):
            st.dataframe(df.head())
            st.write(f"**Dimens√µes:** {df.shape[0]} linhas √ó {df.shape[1]} colunas")

        # Selecionar coluna de texto
        text_col = st.selectbox("Selecione a coluna de texto para an√°lise:", df.columns)

        # Tipo de an√°lise
        st.markdown("---")
        st.subheader("üéØ Tipo de An√°lise")
        
        tipo_analise = st.radio(
            "Selecione o tipo de an√°lise:",
            ["An√°lise de Sentimento", "An√°lise Sint√°tica", "Nuvem de Palavras", "An√°lise Completa"]
        )

        # Configura√ß√µes avan√ßadas
        st.markdown("---")
        with st.expander("üîß Configura√ß√µes Avan√ßadas"):
            # Stopwords personalizadas
            stopwords_input = st.text_area("Stopwords personalizadas (separe por v√≠rgula):", "",
                                          help="Palavras que devem ser ignoradas na an√°lise")
            custom_stopwords = set([w.strip().lower() for w in stopwords_input.split(",") if w.strip()])
            stop_words = set(stopwords.words("portuguese")).union(custom_stopwords)

            # Configura√ß√µes para nuvem
            top_n = st.slider("N√∫mero m√°ximo de palavras:", 50, 500, 100)
            min_chars = st.slider("M√≠nimo de caracteres por palavra:", 1, 10, 3)
            incluir_acentos = st.checkbox("Manter acentos", value=True)

        # Bot√£o de execu√ß√£o
        st.markdown("---")
        executar_analise = st.button("üîç Executar An√°lise", type="primary", use_container_width=True)
        
        # Se clicou em executar an√°lise, armazenar nos estados
        if executar_analise:
            st.session_state.analise_feita = True
            st.session_state.df_original = df.copy()
            st.session_state.text_col = text_col
            st.session_state.tipo_analise = tipo_analise
            st.session_state.stop_words = stop_words
            st.session_state.top_n = top_n
            st.session_state.min_chars = min_chars
            st.session_state.incluir_acentos = incluir_acentos
            st.session_state.custom_stopwords = custom_stopwords
            
            # Executar an√°lises e armazenar resultados
            with st.spinner("Executando an√°lises..."):
                # Vari√°veis para armazenar resultados
                df_analisado = df.copy()
                df_sintatica_result = None
                nuvens_result = {}
                
                # An√°lise de Sentimento
                if tipo_analise in ["An√°lise de Sentimento", "An√°lise Completa"]:
                    with st.spinner("üîÑ Carregando modelo de sentimentos..."):
                        sentiment_analyzer = carregar_modelo_sentimento()
                    
                    with st.spinner("üîÑ Analisando sentimentos..."):
                        try:
                            textos_para_analise = df_analisado[text_col].astype(str).tolist()
                            
                            sentimentos, scores = [], []
                            batch_size = 32
                            
                            for i in range(0, len(textos_para_analise), batch_size):
                                batch = textos_para_analise[i:i + batch_size]
                                batch_resultados = classificar_sentimento_batch(sentiment_analyzer, batch)
                                
                                for sentimento, score in batch_resultados:
                                    sentimentos.append(sentimento)
                                    scores.append(score)
                            
                            df_analisado["SENTIMENTO"] = sentimentos
                            df_analisado["SCORE_SENTIMENTO"] = scores
                            
                        except Exception as e:
                            st.error(f"‚ùå Erro na an√°lise de sentimentos: {e}")

                # An√°lise Sint√°tica
                if tipo_analise in ["An√°lise Sint√°tica", "An√°lise Completa"]:
                    with st.spinner("üîÑ Analisando estrutura sint√°tica..."):
                        try:
                            textos_para_sintaxe = df_analisado[text_col].dropna().head(50)
                            if len(textos_para_sintaxe) > 0:
                                df_sintatica_result = analisar_sintatica(textos_para_sintaxe)
                            else:
                                st.warning("‚ö†Ô∏è N√£o h√° textos v√°lidos para an√°lise sint√°tica.")
                                
                        except Exception as e:
                            st.error(f"‚ùå Erro na an√°lise sint√°tica: {e}")

                # Gerar nuvens
                if tipo_analise in ["Nuvem de Palavras", "An√°lise Completa"]:
                    with st.spinner("üîÑ Gerando nuvens de palavras..."):
                        nuvem_principal = gerar_nuvem(df_analisado[text_col], "Nuvem de Palavras Geral")
                        if nuvem_principal:
                            nuvens_result["nuvem_principal"] = nuvem_principal
                        
                        if "SENTIMENTO" in df_analisado.columns:
                            nuvem_positiva = gerar_nuvem(df_analisado[df_analisado["SENTIMENTO"] == "POSITIVO"][text_col], "Nuvem Positiva")
                            if nuvem_positiva:
                                nuvens_result["nuvem_positiva"] = nuvem_positiva
                            
                            nuvem_negativa = gerar_nuvem(df_analisado[df_analisado["SENTIMENTO"] == "NEGATIVO"][text_col], "Nuvem Negativa")
                            if nuvem_negativa:
                                nuvens_result["nuvem_negativa"] = nuvem_negativa
                            
                            nuvem_neutra = gerar_nuvem(df_analisado[df_analisado["SENTIMENTO"] == "NEUTRO"][text_col], "Nuvem Neutra")
                            if nuvem_neutra:
                                nuvens_result["nuvem_neutra"] = nuvem_neutra
                
                # Armazenar resultados no session state
                st.session_state.df_analisado = df_analisado
                st.session_state.df_sintatica = df_sintatica_result
                st.session_state.nuvens = nuvens_result
                
            st.success("‚úÖ An√°lises conclu√≠das!")
        
    else:
        st.info("üìÇ Envie um arquivo para come√ßar a an√°lise.")
        # Resetar estados se n√£o h√° arquivo
        st.session_state.analise_feita = False
        st.session_state.df_analisado = None
        st.session_state.df_sintatica = None
        st.session_state.nuvens = {}

    # Status do sistema
    st.markdown("---")
    st.header("üìä Status do Sistema")
    st.write(f"**GPU dispon√≠vel:** {'‚úÖ' if torch.cuda.is_available() else '‚ùå'}")
    st.write(f"**An√°lise conclu√≠da:** {'‚úÖ' if st.session_state.analise_feita else '‚ùå'}")

# ========================
# üéØ √ÅREA PRINCIPAL - RESULTADOS
# ========================
# Usar vari√°veis do session state para evitar rerun
if st.session_state.analise_feita and st.session_state.df_analisado is not None:
    df_analisado = st.session_state.df_analisado
    df_sintatica = st.session_state.df_sintatica
    nuvens = st.session_state.nuvens
    text_col = st.session_state.text_col
    tipo_analise = st.session_state.tipo_analise
    stop_words = st.session_state.stop_words
    top_n = st.session_state.top_n
    min_chars = st.session_state.min_chars
    incluir_acentos = st.session_state.incluir_acentos

    # ========================
    # üìä EXIBIR RESULTADOS EM EXPANDERS
    # ========================
    
    # Nuvem Principal
    with st.expander("‚òÅÔ∏è NUVEM PRINCIPAL", expanded=True):
        if tipo_analise in ["Nuvem de Palavras", "An√°lise Completa"]:
            if "nuvem_principal" in nuvens and nuvens["nuvem_principal"]:
                st.image(nuvens["nuvem_principal"], use_column_width=True)
            
            # Bot√£o de download para esta se√ß√£o
            if "nuvem_principal" in nuvens and nuvens["nuvem_principal"]:
                col1, col2 = st.columns(2)
                with col1:
                    st.download_button(
                        label="üì• Baixar Nuvem Principal",
                        data=nuvens["nuvem_principal"].getvalue(),
                        file_name="nuvem_principal.png",
                        mime="image/png",
                        use_container_width=True,
                        key="download_nuvem_principal"
                    )
        else:
            st.info("Selecione 'Nuvem de Palavras' ou 'An√°lise Completa' para ver esta visualiza√ß√£o.")

    # An√°lise de Sentimento
    with st.expander("üß† AN√ÅLISE DE SENTIMENTO", expanded=True):
        if tipo_analise in ["An√°lise de Sentimento", "An√°lise Completa"] and "SENTIMENTO" in df_analisado.columns:
            st.success("‚úÖ An√°lise de sentimento conclu√≠da!")
            
            # M√©tricas
            col1, col2 = st.columns(2)
            with col1:
                contagem_sentimentos = df_analisado["SENTIMENTO"].value_counts()
                st.bar_chart(contagem_sentimentos)
            with col2:
                st.dataframe(contagem_sentimentos)
            
            # Nuvens por sentimento
            st.subheader("‚òÅÔ∏è Nuvens por Sentimento")
            col1, col2 = st.columns(2)
            
            with col1:
                if "nuvem_positiva" in nuvens and nuvens["nuvem_positiva"]:
                    st.image(nuvens["nuvem_positiva"], use_column_width=True)
            
            with col2:
                if "nuvem_negativa" in nuvens and nuvens["nuvem_negativa"]:
                    st.image(nuvens["nuvem_negativa"], use_column_width=True)
            
            col3, col4 = st.columns(2)
            with col3:
                if "nuvem_neutra" in nuvens and nuvens["nuvem_neutra"]:
                    st.image(nuvens["nuvem_neutra"], use_column_width=True)
            
            # Bot√£o de download para esta se√ß√£o
            col1, col2 = st.columns(2)
            with col1:
                # Preparar dados para download
                output_buffer = BytesIO()
                with pd.ExcelWriter(output_buffer, engine='openpyxl') as writer:
                    df_sentimento = df_analisado[[text_col, 'SENTIMENTO', 'SCORE_SENTIMENTO']]
                    df_sentimento.to_excel(writer, sheet_name='An√°lise_Sentimentos', index=False)
                    stats_sentimentos = df_analisado['SENTIMENTO'].value_counts().reset_index()
                    stats_sentimentos.columns = ['Sentimento', 'Quantidade']
                    stats_sentimentos.to_excel(writer, sheet_name='Estat√≠sticas', index=False)
                
                output_buffer.seek(0)
                
                st.download_button(
                    label="üìä Baixar Dados Sentimento",
                    data=output_buffer,
                    file_name="analise_sentimento.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                    key="download_sentimento_excel"
                )
            
            with col2:
                # Criar ZIP com nuvens de sentimento
                nuvens_sentimento = {k: v for k, v in nuvens.items() if k in ['nuvem_positiva', 'nuvem_negativa', 'nuvem_neutra']}
                if nuvens_sentimento:
                    zip_buffer = BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
                        for nome, nuvem in nuvens_sentimento.items():
                            zip_file.writestr(f"{nome}.png", nuvem.getvalue())
                    zip_buffer.seek(0)
                    
                    st.download_button(
                        label="üñºÔ∏è Baixar Nuvens Sentimento",
                        data=zip_buffer,
                        file_name="nuvens_sentimento.zip",
                        mime="application/zip",
                        use_container_width=True,
                        key="download_sentimento_zip"
                    )
        else:
            st.info("Selecione 'An√°lise de Sentimento' ou 'An√°lise Completa' para ver esta an√°lise.")

    # An√°lise Sint√°tica
    with st.expander("üìù AN√ÅLISE SINT√ÅTICA", expanded=True):
        if tipo_analise in ["An√°lise Sint√°tica", "An√°lise Completa"] and df_sintatica is not None:
            st.success(f"‚úÖ An√°lise sint√°tica conclu√≠da! {len(df_sintatica)} palavras analisadas.")
            
            # Estat√≠sticas
            st.subheader("üìä Distribui√ß√£o de Classes Gramaticais")
            contagem_classes = df_sintatica['classe_gramatical'].value_counts()
            col1, col2 = st.columns(2)
            with col1:
                st.bar_chart(contagem_classes)
            with col2:
                st.dataframe(contagem_classes)
            
            # Nuvens por classe gramatical
            st.subheader("‚òÅÔ∏è Nuvens por Classe Gramatical")
            
            col1, col2, col3 = st.columns(3)
            nuvens_sintaticas = {}
            
            with col1:
                nuvem_verbos = gerar_nuvem_por_classe(df_sintatica, "VERB", "Verbos")
                if nuvem_verbos:
                    st.image(nuvem_verbos, use_column_width=True)
                    nuvens_sintaticas["verbos"] = nuvem_verbos
            
            with col2:
                nuvem_adjetivos = gerar_nuvem_por_classe(df_sintatica, "ADJ", "Adjetivos")
                if nuvem_adjetivos:
                    st.image(nuvem_adjetivos, use_column_width=True)
                    nuvens_sintaticas["adjetivos"] = nuvem_adjetivos
            
            with col3:
                nuvem_substantivos = gerar_nuvem_por_classe(df_sintatica, "NOUN", "Substantivos")
                if nuvem_substantivos:
                    st.image(nuvem_substantivos, use_column_width=True)
                    nuvens_sintaticas["substantivos"] = nuvem_substantivos
            
            # Dados detalhados
            with st.expander("üîç Visualizar an√°lise sint√°tica completa"):
                st.dataframe(df_sintatica.head(100))
            
            # Bot√£o de download para esta se√ß√£o
            col1, col2 = st.columns(2)
            with col1:
                output_buffer = BytesIO()
                with pd.ExcelWriter(output_buffer, engine='openpyxl') as writer:
                    df_sintatica.to_excel(writer, sheet_name='An√°lise_Sint√°tica', index=False)
                    stats_classes = df_sintatica['classe_gramatical'].value_counts().reset_index()
                    stats_classes.columns = ['Classe_Gramatical', 'Quantidade']
                    stats_classes.to_excel(writer, sheet_name='Estat√≠sticas', index=False)
                
                output_buffer.seek(0)
                
                st.download_button(
                    label="üìä Baixar Dados Sint√°ticos",
                    data=output_buffer,
                    file_name="analise_sintatica.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                    key="download_sintatica_excel"
                )
            
            with col2:
                if nuvens_sintaticas:
                    zip_buffer = BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
                        for nome, nuvem in nuvens_sintaticas.items():
                            zip_file.writestr(f"nuvem_{nome}.png", nuvem.getvalue())
                    zip_buffer.seek(0)
                    
                    st.download_button(
                        label="üñºÔ∏è Baixar Nuvens Sint√°ticas",
                        data=zip_buffer,
                        file_name="nuvens_sintaticas.zip",
                        mime="application/zip",
                        use_container_width=True,
                        key="download_sintatica_zip"
                    )
        else:
            st.info("Selecione 'An√°lise Sint√°tica' ou 'An√°lise Completa' para ver esta an√°lise.")

    # ========================
    # üì• DOWNLOAD COMPLETO
    # ========================
    st.markdown("---")
    st.subheader("üì¶ Download Completo")
    
    # Criar arquivo ZIP com tudo
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
        # Adicionar Excel com m√∫ltiplas planilhas
        excel_buffer = BytesIO()
        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
            df_analisado.to_excel(writer, sheet_name='Dados_Originais', index=False)
            
            if "SENTIMENTO" in df_analisado.columns:
                df_sentimento = df_analisado[[text_col, 'SENTIMENTO', 'SCORE_SENTIMENTO']]
                df_sentimento.to_excel(writer, sheet_name='An√°lise_Sentimentos', index=False)
                stats_sentimentos = df_analisado['SENTIMENTO'].value_counts().reset_index()
                stats_sentimentos.columns = ['Sentimento', 'Quantidade']
                stats_sentimentos.to_excel(writer, sheet_name='Estat√≠sticas_Sentimentos', index=False)
            
            if df_sintatica is not None:
                df_sintatica.to_excel(writer, sheet_name='An√°lise_Sint√°tica', index=False)
                stats_classes = df_sintatica['classe_gramatical'].value_counts().reset_index()
                stats_classes.columns = ['Classe_Gramatical', 'Quantidade']
                stats_classes.to_excel(writer, sheet_name='Estat√≠sticas_Sint√°ticas', index=False)
        
        excel_buffer.seek(0)
        zip_file.writestr("resultados_analise.xlsx", excel_buffer.getvalue())
        
        # Adicionar todas as nuvens
        for nome, nuvem in nuvens.items():
            zip_file.writestr(f"{nome}.png", nuvem.getvalue())
        
        # Adicionar nuvens sint√°ticas se existirem
        if df_sintatica is not None:
            nuvens_sintaticas = {}
            nuvens_sintaticas["verbos"] = gerar_nuvem_por_classe(df_sintatica, "VERB", "Verbos")
            nuvens_sintaticas["adjetivos"] = gerar_nuvem_por_classe(df_sintatica, "ADJ", "Adjetivos")
            nuvens_sintaticas["substantivos"] = gerar_nuvem_por_classe(df_sintatica, "NOUN", "Substantivos")
            
            for nome, nuvem in nuvens_sintaticas.items():
                if nuvem:
                    zip_file.writestr(f"nuvem_{nome}.png", nuvem.getvalue())
    
    zip_buffer.seek(0)
    
    st.download_button(
        label="üì¶ Baixar ZIP Completo",
        data=zip_buffer,
        file_name="analise_texto_completa.zip",
        mime="application/zip",
        use_container_width=True,
        key="download_completo"
    )

else:
    # Mensagem inicial
    st.markdown("""
    ## üöÄ Bem-vindo ao Analisador de Texto Completo!
    
    **Como usar:**
    1. üìÇ **Upload**: Envie sua planilha na sidebar
    2. ‚öôÔ∏è **Configura√ß√£o**: Selecione coluna e tipo de an√°lise
    3. üîç **Executar**: Clique no bot√£o na sidebar
    4. üìä **Resultados**: Visualize nas se√ß√µes expans√≠veis abaixo
    5. üì• **Download**: Baixe resultados individuais ou completos
    
    **Recursos dispon√≠veis:**
    - ‚òÅÔ∏è **Nuvens de palavras** personaliz√°veis
    - üß† **An√°lise de sentimentos** com RoBERTuito
    - üìù **An√°lise sint√°tica** com Stanza
    - üî§ **Nuvens por classe gramatical** (verbos, adjetivos, substantivos)
    """)
    
    with st.expander("‚ÑπÔ∏è Mais informa√ß√µes"):
        st.markdown("""
        **Tipos de An√°lise:**
        - **Sentimento**: Classifica textos como Positivo/Negativo/Neutro
        - **Sint√°tica**: Analisa estrutura gramatical + nuvens categorizadas
        - **Nuvem**: Visualiza√ß√£o de palavras frequentes
        - **Completa**: Todas as an√°lises combinadas
        
        **Formatos suportados:** CSV, Excel (XLSX)
        **Idioma:** Portugu√™s
        """)

# ========================
# üé® ESTILOS CSS
# ========================
st.markdown("""
<style>
    .main > div {
        padding-top: 1rem;
    }
    .stExpander {
        border: 1px solid #e0e0e0;
        border-radius: 10px;
        padding: 1rem;
        margin-bottom: 1rem;
    }
    .stExpander > div:first-child {
        background-color: #f0f2f6;
        border-radius: 8px;
        padding: 0.5rem 1rem;
    }
</style>
""", unsafe_allow_html=True)
